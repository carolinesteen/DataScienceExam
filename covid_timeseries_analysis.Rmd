---
title: "Untitled"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/DataScience Exam/US_covid")

library(dplyr)
library(ggplot2)
library(tidyr)
library(tidyverse)
library(lubridate)
library(tsibble)
library(tsibbledata) 
library(feasts)
library(fpp3)
library(fabletools)
library(fable)
library(distributional)
library(lme4)
library(tis)
library(prophet)
library(rstan)
library(tseries)

library(directlabels)
```

```{r}
demographics_ny21may <- read_csv("demographics_ny21may.csv")
us_total <- read_csv("us_total21may.csv")
us_total <- us_total %>%
  mutate(date = as_date(date)) %>%
  as_tsibble(index = date)

us_total <- us_total %>%
  mutate(death_season = difference(death_diff, 7))%>%
  mutate(death_season_diff = difference(death_season))

lambda <- us_total %>%
  features(pos_diff, features = guerrero) %>%
  pull(lambda_guerrero)
us_total <- us_total %>%
  mutate(box_cox_POS = box_cox(pos_diff, lambda))

ny_covid <- read_csv("ny_covid21may.csv")
ny_covid <- ny_covid %>%
  mutate(date = as_date(date)) %>%
  as_tsibble(key= state, index = date)

restrictions <- read_csv("restrictions.csv")
restrictions <- restrictions %>%
  mutate(date = as_date(date)) %>%
  as_tsibble(index = date)

par(mfrow=c(1,2))
autoplot(us_total, cases)+
  labs(title = "US - Cumulative COVID-19 cases")+
  theme_minimal()

autoplot(us_total, pos_diff)+
  labs(title = "US - Cases Increase")+
  theme_minimal()

autoplot(us_total, box_cox_POS)+
  labs(title = "US - Cases Increase BoxCox transformed")+
  theme_minimal()

autoplot(us_total, deaths)+
  labs(title = "US - Cumulative COVID-19 deaths")+
  theme_minimal()



autoplot(ny_covid, pos_pop)+
  geom_dl(aes(label = state), method = list(dl.combine("last.points")), cex = 0.5)+
  labs(title = "Normalised Positive cases - US state")+
  ylab("Positive cases")+
  theme_minimal()
autoplot(ny_covid, death_pop)+
  geom_dl(aes(label = state), method = list(dl.combine("last.points")), cex = 0.5)+
  labs(title = "Normalised deaths - US state")+
  ylab("Deaths")+
  theme_minimal()

```




```{r}
dcmp_cases <- us_total %>%
  model(stl = STL(cases))
components(dcmp_cases)
components(dcmp_cases) %>% autoplot() +
  labs(title = "STL decomposition of positive cases")+
  theme_minimal()

dcmp_deaths <- us_total %>%
  model(stl = STL(deaths))
components(dcmp_deaths)
components(dcmp_deaths) %>% autoplot()+
  labs(title = "STL decomposition of deaths")+
  theme_minimal()


```

```{r}
#plots of the seasonally adjusted values for positive increase in cases and deaths 
dcmp_cases_diff <- us_total %>%
  model(stl = STL(pos_diff))
components(dcmp_cases_diff)
components(dcmp_cases_diff) %>% autoplot() +
  labs(title = "Cases - Autoplot of seasonally adjusted and trend values")+
  theme_minimal()

dcmp_deaths_diff <- us_total %>%
  model(stl = STL(death_diff))
components(dcmp_deaths_diff)
components(dcmp_deaths_diff) %>% autoplot() +
  labs(title = "STL decomposition of double differenced positive cases")+
  theme_minimal()

components(dcmp_cases_diff) %>%
  as_tsibble() %>%
  autoplot(pos_diff, colour = "black") +
  geom_line(aes(y=season_adjust), colour = "grey")+
  geom_line(aes(y=trend), colour = "red")+
  labs(title = "Cases - Autoplot of seasonally adjusted and trend values")+
  theme_minimal()

components(dcmp_deaths_diff) %>%
  as_tsibble() %>%
  autoplot(death_diff, colour = "black") +
  geom_line(aes(y=season_adjust), colour = "grey")+
  geom_line(aes(y=trend), colour = "red")+
  labs(title = "Deaths - Autoplot of seasonally adjusted and trend values")+
  theme_minimal()

autoplot(us_total, difference(cases, 7))
autoplot(us_total, difference(deaths, 7))

```

```{r}
us_total %>% gg_subseries(pos_diff)

us_total %>%
  gg_lag(pos_diff_diff, geom = "point") +
  labs(x = "lag(Beer, k)")

us_total %>%
  ACF(pos_diff, max_lag=100) %>%
  autoplot()

us_total %>%
  ACF(death_diff, max_lag=100) %>%
  autoplot()
```



```{r}
us_total_ma <- us_total %>%
  mutate(
    `7-MA` = slider::slide_dbl(pos_diff, mean,
                .before = 0, .after = 0, .complete = TRUE),
    `2x7-MA` = slider::slide_dbl(`7-MA`, mean,
                .before = 0, .after = 0, .complete = TRUE)
  )
us_total_ma %>%
  autoplot(pos_diff, colour = "gray") +
  geom_line(aes(y = `2x7-MA`), colour = "#D55E00")
```




```{r}
us_features_cases <- us_total %>%
  features(cases, feature_set(pkgs = "feasts"))
us_features_cases

# trend_strength 0.9999993
# seasonal_strength_week 0.4327512
# seasonal_peak_week 4

us_features_deaths <- us_total %>%
  features(deaths, feature_set(pkgs = "feasts"))
us_features_deaths
# trend_strength 0.9999984
# seasonal_strength_week 0.7981068
# seasonal_peak_week 4
```

```{r}
autoplot(us_total, pos_diff)+
  labs(title = "Positive increase in cases")+
  theme_minimal()
autoplot(us_total, death_diff)+
  labs(title = "Positive increase in deaths")+
  theme_minimal()
```

```{r}
aus_exports <- us_total %>%
  mutate(`16-MA` = slider::slide_dbl(pos_diff, mean, .before = 8, .after = 8, .complete = TRUE))

aus_exports %>%
  autoplot(pos_diff) +
  geom_line(aes(y = `16-MA`), colour = "#D55E00") +
  labs(y = "Positive Cases",
       title = "Increase in Positive Cases") +
  guides(colour = guide_legend(title = "series"))
```





```{r}
ETS_fit_cases <- us_total %>%
  model(ETS(cases))
report(ETS_fit_cases)

components(ETS_fit_cases) %>%
  autoplot() +
  labs(title = "ETS(A,A,A) components")

ETS_fit_deaths <- us_total %>%
  model(ETS(deaths))
report(ETS_fit_deaths)
components(ETS_fit_deaths) %>%
  autoplot() +
  labs(title = "ETS(A,Ad,N) components")

ETS_fit_increase <- us_total %>%
  model(ETS(pos_diff))
report(ETS_fit_increase)
#Model: ETS(A,Ad,A) 
components(ETS_fit_increase) %>%
  autoplot() +
  labs(title = "ETS(A,Ad,A) components")
# chooses the model with additive error, additive dampend trend and additive seasonality 

ETS_fit_increase_death <- us_total %>%
  model(ETS(death_diff))
report(ETS_fit_increase_death)
# Series: death_diff 
# Model: ETS(A,N,A) 
components(ETS_fit_increase_death) %>%
  autoplot() +
  labs(title = "ETS(A,N,A) components")
#
```

```{r}

```


```{r}
# checking the residuals of the ETS and ARIMA models for cases 
us_total %>%
  model(ETS(cases)) %>%
  gg_tsresiduals()
us_total %>%
  model(ARIMA(cases)) %>%
  gg_tsresiduals()
# we see that for the ets model... 
#The mean of the residuals is close to zero and there is no significant correlation in the residuals series.
# The time plot of the residuals shows that the variation of the residuals stays more or less the same across the historical data, apart from the outliers at the end of the year. I am therefore, not sure that the residual variance can be treated as constant.
# thr  histogram of the residuals indicate that the residuals are normally distributed 
# for the arima model...
# there is more correlation in the acf plot, suggesting that the model can be improved, historgam also looks left skewed 

us_total %>%
  model(ETS(deaths)) %>%
  gg_tsresiduals()
us_total %>%
  model(ARIMA(deaths)) %>%
  gg_tsresiduals()
# for the ets model..
# the acf plot shows us that there is significant correlation, sugesting a  weekly seasonal component 
# for the arima model...
# the resiguals are more stable and the acf shows less correlation 
```

```{r}
aug <- us_total %>%
  model(ETS(pos_diff)) %>%
  augment()

aug %>% features(.innov, ljung_box, lag = 10, dof = 0)
```




```{r}
train <- us_total[0:400,]
test <- us_total[401:483,]
test <- test %>%
  mutate(date = as_date(date)) %>%
  as_tsibble(index = date)

train_fit <- train %>%
  model(
    `Simple Exponential method` = ETS(cases ~ error("A") + trend("N") + season("N")),
    `Holt's method` = ETS(cases ~ error("A") + trend("A") + season("N")),
    `Additive Holt's method` = ETS(cases ~ error("A") + trend("A") + season("A")),
    `Damped Holt's method` = ETS(cases ~ error("A") + trend("Ad") + season("N")),
    )


train_fc <- train_fit %>%
  forecast(h = 83)

train_fc %>%
  autoplot(us_total, level = NULL) +
  labs(
    y = "Positive Cases",
    title = "Positive COVID 19 Cases in the US"
  ) +
  guides(colour = guide_legend(title = "Forecast"))+
  theme_minimal()

accuracy(train_fc, test)
```


```{r}
train_fit_deaths <- train %>%
  model(
    `Holt's method` = ETS(deaths ~ error("A") + trend("A") + season("N")),
    `Additive Holt's method` = ETS(deaths ~ error("A") + trend("A") + season("A")),
    `Damped Holt's method` = ETS(deaths ~ error("A") + trend("Ad") + season("N")), 
    `Additive Damped Holt's method` = ETS(deaths ~ error("A") + trend("Ad") + season("A")), 
    `Simple Exponential method` = ETS(deaths ~ error("A") + trend("N") + season("N")))

train_fc_deaths <- train_fit_deaths %>%
  forecast(h = 83)

train_fc_deaths %>%
  autoplot(us_total, level = NULL) +
  labs(
    y = "Nr of deaths from COVID 19",
    title = "Deaths from COVID 19 in the US"
  ) +
  guides(colour = guide_legend(title = "Forecast"))+
  theme_minimal()

accuracy(train_fc_deaths, test)

components(dcmp_deaths_diff) %>%
  as_tsibble() %>%
  autoplot(death_diff, colour = "black") +
  geom_line(aes(y=season_adjust), colour = "grey")+
  geom_line(aes(y=trend), colour = "red")+
  labs(title = "Deaths - Autoplot of seasonally adjusted and trend values")+
  theme_minimal()
```

```{r}
fit_cases_diff <- train %>%
  model(
    additive = ETS(pos_diff ~ error("A") + trend("A") +
                                                season("A")),
    multiplicative = ETS(pos_diff ~ error("M") + trend("A") +
                                                season("M")),
    multiplicative_dampend = ETS(pos_diff ~ error("M") + trend("Ad") +
                                                season("M")))
fc_cases_diff <- fit_cases_diff  %>% forecast(h = 83)
fc_cases_diff %>%
  autoplot(us_total, level = NULL) +
  labs(title="Positive Increase Covid Cases US",
       y="Positive Cases") +
  guides(colour = guide_legend(title = "Forecast"))
accuracy(fc_cases_diff, test)
```

####--------Stationarity --------####
```{r}
#We use the KPSS test to determine the appropriate number of first differences for both variables 
us_total %>%
  features(cases, unitroot_ndiffs) # 2
us_total %>%
  features(deaths, unitroot_ndiffs) # 2
#from the result we see that both varibales need two numbers of first differencing 


# We use the unitroot_nsdiffs() to determine whether seasonal differencing is required
us_total %>%
  features(cases, unitroot_nsdiffs) # 0
# for cases, no seasonal differencing is required 
us_total %>%
  features(deaths, unitroot_nsdiffs) # 1
# for deaths, a seasonal differencing is reqired 

# Because unitroot_nsdiffs() returns 1 for deaths (indicating one seasonal difference is required), we apply the unitroot_ndiffs() function to the seasonally differenced data to see whether we need a first differencing also 
us_total %>%
  mutate(seasonal_diff = difference((deaths), 7)) %>%
  features(seasonal_diff, unitroot_ndiffs) # 1
# returns 1, indicating that we should do a seasonal difference and a first difference.
us_total %>%
  mutate(seasonal_diff = difference((deaths), 7)) %>%
  mutate(death_season_diff = difference(seasonal_diff))%>%
  features(death_season_diff, unitroot_ndiffs) # 0
# returns zero - so we should be able to use the differenced data to determine an appropriate arima model 

```

####--------Stationarity on positive increase  --------####
```{r}
#We use the KPSS test to determine the appropriate number of differences for both increase variables 
us_total %>%
  features(pos_diff, unitroot_ndiffs) # 1
us_total %>%
  features(death_diff, unitroot_ndiffs) # 1
#from the result we see that both varibales need 1 numbers of first differencing 


# We use the unitroot_nsdiffs() to determine whether seasonal differencing is required
us_total %>%
  features(pos_diff, unitroot_nsdiffs) # 0
# for cases, no seasonal differencing is required 
us_total %>%
  features(death_diff, unitroot_nsdiffs) # 1
# for deaths, a seasonal differencing is reqired 

# Because unitroot_nsdiffs() returns 1 for deaths (indicating one seasonal difference is required), we apply the unitroot_ndiffs() function to the seasonally differenced data to see whether we need a first differencing also 
us_total %>%
  mutate(seasonal_diff = difference((death_diff), 7)) %>%
  features(seasonal_diff, unitroot_ndiffs) # 0
# returns 0, indicating that we should not do a seasonal difference and a first difference.


autoplot(us_total, pos_diff_diff)+
  labs(title = "Cases - Autoplot of first differenced series")+
  ylab("Daily Increase in Cases")+
  theme_minimal()
autoplot(us_total, death_season_diff)+
  labs(title = "Deaths - Autoplot of seasonal and first differenced series")+
  theme_minimal()+
  ylab("Daily Increase in Deaths")
  

```

```{r}
us_total %>%
  gg_tsdisplay(difference(cases) %>% difference(),
               plot_type='partial', lag=36) +
  labs(title = "Cases differenced", y="")

us_total %>%
  gg_tsdisplay(difference(death_season) %>% difference(),
               plot_type='partial', lag=36) +
  labs(title = "Deaths Double differenced", y="")


```





```{r}
fit_arima <- us_total %>%
  model(
    arima012011 = ARIMA(pos_diff ~ pdq(0,1,2) + PDQ(0,1,1)),
    arima210011 = ARIMA(pos_diff ~ pdq(2,1,0) + PDQ(0,1,1)),
    auto = ARIMA(pos_diff, stepwise = FALSE)
  )
fit_arima %>% pivot_longer(everything(), names_to = "Model name",
                     values_to = "Orders")
```

```{r}

```



```{r}
# ACF helps determine the number of moving average terms (MA) q
us_total %>%
  ACF(pos_diff_diff, lag_max = 50 ) %>%
  autoplot()
# in the acf we see a spike at 0 and 7 

# PACF helps determine the order of autoregressive terms (AR) p
us_total %>%
  PACF(pos_diff_diff, lag_max = 50 ) %>%
  autoplot()
# in the pacf we see a spike at 0 and declining to 7 

us_total %>%
  ACF(death_season_diff, lag_max = 50 )%>%
  autoplot()
# in the acf we see a spike at 0 and ceclining to 7 

us_total %>%
  PACF(death_season_diff, lag_max = 50 )%>%
  autoplot()
# in the acf we see a spike at 0 and ceclining rapidly to 7 
  
autoplot(us_total, death_diff_diff)

autoplot(a, death_season_diff)

autoplot(us_total, death_diff_diff)

#Looking at our autocorrelation plots we can see that our data is not stationary and From our autocorrelation plots performed on the raw cases, differenced and double differenced we can see that in order to run an arima model we will have to double difference our variables. We do also see that our variables are not purly white noise after double differencing 
```

```{r}
us_total %>%
  gg_tsdisplay(difference(pos_diff, 7),
               plot_type='partial', lag=50)
us_total %>%
  gg_tsdisplay(difference(pos_diff),
               plot_type='partial', lag=50)

us_total %>%
  gg_tsdisplay(difference(death_diff, 7),
               plot_type='partial', lag=50)

us_total %>%
  gg_tsdisplay(difference(death_diff),
               plot_type='partial', lag=50)
```

```{r}
caf_fit_cases <- us_total %>%
  model(arima021 = ARIMA(cases ~ pdq(0,2,1) + PDQ(0,0,2)),
        arima111 = ARIMA(cases ~ pdq(1,1,1) + PDQ(2,1,0)),
        arima111 = ARIMA(cases ~ pdq(1,1,1) + PDQ(2,1,0)),
        arima312 = ARIMA(cases ~ pdq(3, 1, 2) + PDQ(1,0,0)),
        stepwise = ARIMA(cases),
        search = ARIMA(cases, stepwise=FALSE, greedy=FALSE, approximation = FALSE))

caf_fit_cases %>% pivot_longer(everything(), names_to = "Model name",
                         values_to = "Orders")


#<ARIMA(3,2,2)(1,0,0)[7]>

glance(caf_fit_cases) %>% arrange(AICc) %>% select(.model:BIC)

caf_fit_cases %>%
  select(arima111) %>%
  gg_tsresiduals()
```

```{r}
caf_fit_cases_diff <- train %>%
  model(arima021 = ARIMA(pos_diff ~ pdq(0,2,1) + PDQ(0,0,2)),
        arima111 = ARIMA(pos_diff ~ pdq(1,1,1) + PDQ(2,1,0)),
        arima312 = ARIMA(pos_diff ~ pdq(3, 1, 2) + PDQ(1,0,0)),
        stepwise = ARIMA(pos_diff),
        search = ARIMA(pos_diff, stepwise=FALSE, approximation = FALSE))

caf_fit_cases_diff %>% pivot_longer(everything(), names_to = "Model name",
                         values_to = "Orders")


#<ARIMA(3,2,2)(1,0,0)[7]>

glance(caf_fit_cases_diff) %>% arrange(AICc) %>% select(.model:BIC)

caf_fit_cases_diff %>%
  select(arima111) %>%
  gg_tsresiduals()
```


```{r}
caf_fit_deaths <- us_total %>%
  model(arima021 = ARIMA(deaths ~ pdq(0,2,1) + PDQ(0,0,2)),
        arima113 = ARIMA(deaths ~ pdq(1,1,3) + PDQ(0,1,1)),
        stepwise = ARIMA(deaths),
        search = ARIMA(deaths, stepwise=FALSE, greedy=FALSE, approximation = FALSE))

caf_fit_deaths %>% pivot_longer(everything(), names_to = "Model name",
                         values_to = "Orders")

glance(caf_fit_deaths) %>% arrange(AICc) %>% select(.model:BIC)
```


```{r}
fit <- train %>%
  model(
    arima111 = ARIMA(cases ~ pdq(1,1,1) + PDQ(2,1,0)),
    arima322 = ARIMA(cases ~ pdq(3,2,2) + PDQ(0,0,1)),
    `Additive Holt's method` = ETS(cases ~ error("A") + trend("A") + season("A")))
fit
    #<ETS(A,A,A)> 	<ARIMA(0,2,1)(0,0,2)[7]>
fit %>%
  select(arima111, arima322, `Additive Holt's method`) %>%
  coef()
# ma1
# sma1
# sma2
fit %>%
  glance()
fit %>%
  select(arima111, arima322,`Additive Holt's method`) %>%
  report()
fit %>%
  augment()

fit %>%
  accuracy() %>%
  arrange(MASE)
fc <- fit %>%
  forecast(h = 83)
fc %>%
  autoplot(us_total)+
  theme_minimal()
fc %>% 
  accuracy(test)

#for cases it seems that the arima model does best on the training data, however, the ets model does better on forecasting the test data 
# Mean absolute percentage error: MAPE
#ets: 0.47
#arima: 2.59

```


```{r}
fit <- train %>%
  model(
    `Damped Holt's method` = ETS(deaths ~ error("A") + trend("Ad") + season("N")), 
    arima411 = ARIMA(deaths ~ pdq(4,1,1) + PDQ(0,1,1)),
    arima113 = ARIMA(deaths ~ pdq(1,1,3) + PDQ(0,1,1)),
    arima520 = ARIMA(deaths ~ pdq(5,2,0)+ PDQ(0,0,1)))
fit 

fit %>%
  select(arima411, arima113, arima520, `Damped Holt's method`) %>%
  coef()
fit %>%
  glance()
fit %>%
  select(arima411, arima113, arima520, `Damped Holt's method`) %>%
  report()
fit %>%
  augment()
fit %>%
  accuracy() %>%
  arrange(MASE)
fc <- fit %>%
  forecast(h = 83)
fc %>%
  autoplot(us_total)+
  theme_minimal()
fc %>%
  accuracy(test)

# for deaths it also seems that the ets model performs best on the test data 
# MAPE: ets 2.24
# MAPE: arima 4.79
```

```{r}
#fitting on the transformed variable
fit_trans <- train %>%
  model(
    ets = ETS(box_cox),
    arima = ARIMA(box_cox))
fit
fit_trans %>%
  select(arima, ets) %>%
  coef()

fit_trans %>%
  glance()
fit_trans %>%
  select(arima, ets) %>%
  report()
fit_trans %>%
  augment()
fit_trans %>%
  accuracy() %>%
  arrange(MASE)
fc_trans <- fit_trans %>%
  forecast(h = 83)
fc_trans %>%
  autoplot(us_total)
fc_trans %>% 
  accuracy(test)
```





```{r}
install.packages("fpp2")
library(fpp2)
Y <- ts(us_total[,2])

autoplot(Y)
DY <- diff(Y)
DDY <- diff(DY)
autoplot(DY)
ggseasonplot(DDY)

Acf(Y)
Pacf(Y)
Acf(DY)
Pacf(DY)
print(adf.test(DY))

fitA <- auto.arima(DY, stepwise=FALSE, approximation = FALSE, trace=TRUE) # ARIMA(3,1,2) 14912.72
tsdisplay(residuals(fitA), max_lag=40, main="ARIMA(3,1,2)")

fitA <- auto.arima(Y, stepwise=FALSE, approximation = FALSE, trace=TRUE)
tsdisplay(residuals(fitA), max_lag=40, main="ARIMA(3,1,2)")

fitA <- arima(DY, order=c(3,1,2))
tsdisplay(residuals(fitA), max_lag=40, main="ARIMA(3,1,2)")

fitB <- arima(DY, order=c(3,1,21))
tsdisplay(residuals(fitB), max_lag=40, main="ARIMA(3,1,21)")

fitC <- arima(DY, order=c(1,1,1))
tsdisplay(residuals(fitB), max_lag=40, main="ARIMA(1,1,1)")

fitD <- arima(DY, order=c(0,2,1))
tsdisplay(residuals(fitB), max_lag=40, main="ARIMA(0,2,1)")

forecast1 <- forecast(fitA, h=40)
forecast2 <- forecast(fitB, h=40)
forecast3 <- forecast(fitC, h=40)
forecast4 <- forecast(fitD, h=40)
plot(forecast1)
plot(forecast2)
plot(forecast3)
plot(forecast4)

accuracy(forecast1)
accuracy(forecast2)


fit <- snaive(DY)
print(summary(fit)) #
#Residual sd: 18444.2231
checkresiduals(fit)
```

```{r}
fit_ets <- ets(DY)
print(summary(fit_ets)) #ETS(A,A,N) sigma 16051 (A, Ad, N) for differenced 
checkresiduals(fit_ets)
```

```{r}
fit_arima <- auto.arima(Y, d=1, D=1, stepwise=FALSE, approximation = FALSE, trace=TRUE)
print(summary(fit_arima)) 
checkresiduals(fit_arima)
# Series: Y 
# ARIMA(3,1,0) with drift
#16441.99
sqrt(270339151)
```
```{r}
fit_arima2 <- auto.arima(Y, stepwise=FALSE, approximation = FALSE, trace=TRUE)
print(summary(fit_arima2)) #Best model: ARIMA(3,2,2)  
checkresiduals(fit_arima2)
```
```{r}
Z <- ts(us_total[,3])
LZ <- log(Z)
DZ <- diff(Z)
Acf(DZ)
Pacf(DZ)
DDZ <- diff(DZ)
autoplot(DZ)
ggseasonplot(Z)

fit_etsZ <- ets(Z)
print(summary(fit_etsZ))
checkresiduals(fit_etsZ)
#ETS(A,Ad,N) sd 528.9818

fit_arimaZ <- auto.arima(Z,stepwise=FALSE, approximation = FALSE, trace=TRUE)
print(summary(fit_arimaZ))
checkresiduals(fit_arimaZ)
# ARIMA(5,1,0) sd 456.7768
```

```{r}
frst_ets <- forecast(fit_ets, h=50)
autoplot(frst_ets)
frst <- forecast(fit_arima2, h=50)
autoplot(frst)
```


###------- SUBSETS OF State of Interest (SOI) ---------####
```{r}
SOI_ny <- subset(ny_covid, state=="NY" | state=="VT" | state=="ND" | state=="LA" | state=="MA" | state=="CA" | state=="FL" | state=="CT")

SOI_ny <- SOI_ny %>%
  mutate(date = as_date(date)) %>%
  as_tsibble(key=state, index = date)

dcmp_SOI <- SOI_ny %>%
  model(stl = STL(pos_pop))
components(dcmp_SOI)
components(dcmp_SOI) %>% autoplot()

autoplot(SOI_ny, pos_pop)+
  geom_dl(aes(label = state), method = list(dl.combine("last.points")), cex = 0.1) 

autoplot(SOI_ny, death_pop)+
  geom_dl(aes(label = state), method = list(dl.combine("last.points")), cex = 0.1) 

autoplot(SOI_ny, deaths_pos_pop)+
  geom_dl(aes(label = state), method = list(dl.combine("last.points")), cex = 0.1) 
```


```{r}
SOI$state.x.x <- rename(SOI, state.x.x = state)
  
ggplot(SOI_DF, aes(x= reorder(state, -gdp_capita), y=gdp_capita, label=gdp_capita, fill=state)) +
  geom_bar(stat='summary', width=.5)  +
  scale_x_discrete(position = "bottom")
  
```

```{r}
autoplot(SOI, workplaces)
```

